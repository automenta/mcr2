# üß† MCR: The Neurosymbolic Reasoning Core

**Model Context Reasoner (MCR)** is a library designed to be the foundation for the next generation of AI systems. It fuses the perceptual power of Large Language Models (LLMs) with the rigorous logic of symbolic reasoners, creating a hybrid system that is both intuitive and verifiable.

This is not just a tool; it is the starting point for building the ultimate neurosymbolic reasoner‚Äîan AI that can understand the world, reason about it with logical precision, and explain its conclusions.

## üèõÔ∏è Core Principles

MCR is built on a foundation designed for limitless growth.

1.  **Symbolic Core, Neural Interface:** At its heart is a deterministic, verifiable logic engine (Prolog). LLMs act as a fluid, intuitive interface, translating the unstructured, ambiguous human world into the structured, logical core.
2.  **Explainable by Design:** Every conclusion can be traced back to the specific facts and rules that produced it. The system can always "show its work," providing a level of transparency impossible with purely neural systems.
3.  **Dynamic Knowledge Graph:** The knowledge base is not a static set of facts but a living, dynamic graph that is continuously updated and refined through interaction.
4.  **Evolvable Reasoning:** The methods for translating language to logic (**Translation Strategies**) are designed to be pluggable, comparable, and ultimately, evolvable. The system is built to learn and improve its own reasoning processes over time.

## ‚ú® Features (The Foundation)

*   **Library-First API**: A clean, modern `async/await` API that integrates directly into your application.
*   **Stateful Reasoning Sessions**: Create isolated reasoning contexts, each with its own independent, persistent knowledge graph.
*   **Pluggable LLMs & Strategies**: Swap LLM providers and reasoning strategies with configuration changes.
*   **Direct & Hybrid Reasoning**: Execute pure symbolic logic for speed and precision, or allow the system to fall back to the LLM for sub-symbolic queries when formal deduction yields no answer.
*   **Rich, Explainable Outputs**: Queries don't just return an answer; they return the answer *and* the logical steps used to find it.

## üöÄ Quick Start

**1. Install:**

```bash
npm install model-context-reasoner
```

**2. Configure:**

Create a `.env` file with your LLM API key.

```dotenv
# .env
OPENAI_API_KEY="sk-..."
```

**3. Build a Reasoner:**

The core workflow is to create a session, populate its knowledge graph, and then ask it to reason about that knowledge.

```javascript
// main.js
require('dotenv').config();
const { MCR } = require('model-context-reasoner');

async function main() {
  const mcr = new MCR({
    llm: { provider: 'openai', apiKey: process.env.OPENAI_API_KEY }
  });
  
  const session = mcr.createSession();
  
  await session.assert('All canaries are birds.');
  await session.assert('All birds have wings.');
  await session.assert('Tweety is a canary.');
  
  // Query with Prolog
  const prologResult = await session.query('has_wings(tweety)');
  console.log(`Prolog answer: ${prologResult.success ? 'Yes' : 'No'}`);
  
  // Query with natural language
  const naturalResult = await session.nquery('Does tweety have wings?');
  console.log(`Natural language answer: ${naturalResult.success ? 'Yes' : 'No'}`);
  
  // Reason about task
  const reasoning = await session.reason('Can tweety fly?');
  console.log(`Reasoning: ${reasoning.answer}`);
  console.log(`Steps: ${reasoning.steps.join('\n')}`);
}

main().catch(console.error);
```

**Expected Output:**

```
Prolog answer: Yes
Natural language answer: Yes
Reasoning: Yes
Steps:
Translated: has_wings(tweety)
Executed: has_wings(tweety)
Result: true
```

## üì¶ API Reference

### `MCR` Class

*   `new MCR(config)`: Creates a new MCR instance.
*   `createSession(options)`: Creates and returns a new `Session` object.

---

### `Session` Class

Represents an isolated reasoning context and its knowledge graph.

*   `async assert(naturalLanguageText)`: Translates a statement into a symbolic representation and integrates it into the knowledge graph. Returns an `integrationReport` detailing what was added.
*   `async query(prologQuery)`: Executes a Prolog query against the knowledge graph.
    *   **Returns**: An object containing:
        *   `success`: A boolean indicating whether the query succeeded
        *   `bindings`: A string representing variable bindings or null
        *   `explanation`: Array of Prolog queries used in reasoning
*   `async nquery(naturalLanguageQuery)`: Translates natural language question to Prolog and executes query.
    *   **Returns**: Same object as `query()`
*   `async reason(taskDescription)`: Uses translation and query to provide natural language reasoning.
    *   **Returns**: An object containing:
        *   `answer`: 'Yes' or 'No' based on query result
        *   `steps`: Array of reasoning steps
*   `getKnowledgeGraph()`: Returns the entire knowledge graph as a Prolog string.

## üß† Core Concepts: The Path to AGI

The simple API above is the interface to a powerful set of underlying concepts designed for future growth.

### Translation Strategies

A Translation Strategy is a "pluggable mind" for the reasoner. It defines how to convert between the neural and symbolic worlds. The initial library will include basic strategies (e.g., "Direct-to-Prolog"), but the architecture is designed for advanced strategies that can:

*   Use a **Structured Intermediate Representation** (e.g., JSON) to eliminate LLM syntax errors.
*   Perform **self-correction** by re-prompting the LLM upon failure.
*   Query **external tools and APIs** to gather new knowledge before asserting it.

### The Dynamic Knowledge Graph

The "KB" is more than a static database. It's a graph that can be actively shaped and constrained by **ontologies**. You can provide an ontology that defines the "shape" of the world‚Äîthe types of entities that exist and the relationships they can have. This allows the reasoner to:

*   Identify and reject nonsensical assertions ("Socrates is a color").
*   Ask clarifying questions when faced with ambiguity.
*   Infer missing information based on the defined structure of the world.

### The Hybrid Reasoning Engine

MCR is designed for **hybrid reasoning**. While the Prolog core provides speed and verifiability, some questions are inherently sub-symbolic ("What is the sentiment of this sentence?"). The `query` method's `allowSubSymbolicFallback` option is the entry point to this hybrid capability, allowing the system to seamlessly choose the right tool for the job.

## üõ£Ô∏è The Road Ahead: Future Directions

MCR is architected to evolve. The foundational features are the launchpad for a system that will progressively gain more advanced, autonomous capabilities.

*   **Strategy Evolution**: The system will log the performance (latency, accuracy, cost) of its Translation Strategies. This data will be used to create a feedback loop, allowing an "optimizer" process to critique, refine, and generate new, more effective strategies automatically.
*   **Automated Knowledge Acquisition**: Future versions will be able to ingest and understand unstructured documents, websites, or API documentation, automatically building and updating their own knowledge graphs.
*   **Multi-Modal Reasoning**: The architecture is designed to support future strategies that can translate inputs from other modalities‚Äîsuch as image recognition or data streams‚Äîinto the symbolic core, enabling reasoning across different types of information.
*   **Goal-Oriented Agency**: The `reason()` method will evolve into a true agentic loop, allowing the system to autonomously break down complex goals into smaller, solvable steps of assertion and querying.
